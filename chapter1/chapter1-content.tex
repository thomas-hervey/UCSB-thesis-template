\chapter{Introduction} \label{ch:[chapter 1 label]}

Search on the web dominates modern \gls{information_retrieval} (\acrfull{IR}) tasks. However, this wasn't always the case. Not long ago, people relied on physical references for information to answer their questions such as encyclopedias and phone books. Using these meticulously constructed resources requires patience and an ability to follow your nose and/or support from an expert like a librarian. But with the introduction of web search systems, it became significantly faster and arguably easier to find answers. Many web users set Google or Wikipedia as their browser’s homepage and issue hundreds of queries a day. People have become so reliant on web search systems that we inevitably and perhaps inadvertently defer to them when we’re asked questions by other people. In a sense, people have become impatient with the IR process and are highly expectant of search systems. So, because of their value and influence, search systems are heavily studied and continually improved in order to serve more relevant information.

Arguably the most critical IR improvements are to search \emph{effectiveness}, and in particular comprehension of relevance in search. Search effectiveness is a search system’s relative ability of interpreting queries, producing and ordering a ranked list of relevant documents, and presenting them to the user. \emph{\gls{relevance}} is how important a document is to a user’s needs. It is an elusive but critical component of search effectiveness. In practice, search systems attempt to capture relevance by comparing a user’s query and indexed documents for similarity. The more similar a document is to a query, the more relevant it is assumed to be.

Ultimately, supplying highly relevant documents is fundamental to a system’s usefulness and a user’s understanding and satisfaction. Google, for example, is the most popular industry provider of web page search because it was the first company to make a significant improvement to a relevance ranking algorithm. In their beginning, Google used web page popularity as a criteria for relevance. Now, as a competitive industry power, Google continually gathers data on user search behavior to better understand relevance, what constitutes a highly relevant result, and then improve their web page ranking algorithm accordingly. Thus far, their strategy is working. Google has billions of users, many of whom expect the top five search results to be very relevant and almost never explore beyond the first page of results \cite{Manning2008}.

Google’s IR research model is powerful but information needs are expanding. Satisfying these needs requires data, not just web pages. Searchable and interactive data catalogs on the web called data \emph{portals} are ballooning, driven by academics who encourage data sharing \cite{Lafia2016} and governments that want to demonstrate transparency \cite{Pereira2017}, among others. For example, Google’s Dataset Search \footnote{\url{https://toolbox.google.com/datasetsearch}} portal indexes thousands of academic datasets across the world and Esri's OpenData geospatial data portals house geospatial data published by thousands of municipalities. Unfortunately, unlike mature search systems that serve web pages, data portals handle complex and multidimensional datasets that aren't as easy to systematically index or reason on. Therefore, understanding what makes a dataset relevant is paramount for guiding sustainable development of these portals.

Of particular difficulty is serving relevant \emph{\gls{geospatial_datasets}}. In 2007, it was argued that over 18\% of web search queries are geographic in nature \cite{Sanderson2007}, and this percentage is likely significantly higher for queries issued to geospatial data portals (herein referred to as \emph{\gls{portals}}). So, what does a serving a relevant geospatial dataset mean? Perhaps surprisingly, this is not agreed upon by the \gls{geographic_information_retrieval} (\acrshort{GIR}) community. Relevance is typically borrowed from the IR community with a slight twist on \gls{geographic_relevance} (\acrshort{GR}). A geospatial dataset is deemed geographically relevant if it’s spatial footprint has a simple overlap with places in a query. This overlap criteria is combined with syntactic criteria, such as keyword similarity, and a final document scores are computed. No other criteria are used to calculate relevance such as geographical concepts like topology, density, shape, or spatial granularity. Geography plays a limited role in portal search. Furthermore, portals have limited search facets, the options a user can control to specify their query. For example, few portals have visual or map-based interfaces, and no facets that relate to geography. As a result, portal users have little intuition about or control over the search process. Ultimately, many of them abandon their searches.

So, how can we reduce search abandonment on portals? What is a way to make results more relevant to users? In this PhD research proposal, I will outline my plan to address these broad questions. Specifically, in the next section, I will discuss background on what \gls{geographic_information_needs} (\acrshort{GIN}s) are, what the GIR currently considers GR to be, and how GINs and GR fit into a broader context of \gls{information_need} and relevance. Following the background, I will discuss the motivating problem of search abandonment on portals and how it is partially caused by a lack of relevant search results. Next, I will discuss my guiding research question on how to improve search on portals and my hypothesis for doing so. Following this, I will discuss research objectives as well as previous work. Lastly, I will outline my research design and methods including individual study procedures, expected results, research significance, current progress, and a timeline for completion.

[TODO]*bring up concepts earlier! This needs to be*
