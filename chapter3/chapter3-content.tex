\chapter{Problem and Research Question} \label{ch:[chapter 3 label]}

\section{Problem Statement}

The motivating problem for this research is as follows:
\linebreak

\emph{Many search sessions on geospatial data portals end in failure or are abandoned.}
\linebreak

This problem is confirmed by recorded user search behavior on Esri's OpenData geospatial data portals (portals). By the end of a search session, few users complete a goal conversion  such as download a dataset. It is much more likely that a user will execute a search, refine that search several times, and then exit the session. While there can be many reasons for search abandonment, search ineffectiveness is often a leading cause, as it is in this case.*QUANTIFY exit and abandonment* This behavior indicates that users cannot find relevant datasets that satisfy their needs. There are a number of related reasons for this failure.

First, portals use simplistic techniques for comparing a user's query to datasets. Most search systems rely primarily on syntactic similarity to rank documents. For example, a top SERP result on a is placed at the top because it shares more words with a user's query than any other result. This approach is intuitive but suffers from a number of drawbacks including bias towards larger and wordier dataset representations, agnosticism towards user context, and a very weak application of geography. There are many successful algorithmic adjustments to this ranking approach, but ultimately its design handles semantics weakly. Second, simplistic techniques are used because developers have a hard time applying knowledge about user needs. It is technically difficult to index datasets, especially when they're heterogeneous and vary in completeness. Once datasets are indexed, reasoning on them is even more difficult. For example, how should a developer know which metadata are most important and how to weigh them in a ranking algorithm? There are machine learning approaches that can guide this process, but typically developers end up using heuristics and commercial goals to guide design. Once a basic ranking algorithm is created, developers tend to focus on adding new features. Third, a weak understanding of GR means that there is little knowledge to guide indexing and ranking development. GR is not well understood or agreed upon in the GIR community \cite{Purves2018}. As a result, GIR systems treat relevance as something more basic than it is. Current indexing and ranking methods can't capture rich enough understanding of relevance because we don't know what explicit and implicit concepts (both geospatial and non-geospatial) that users use when searching.

Given these reasons, it’s understandable why portals only use simple spatial similarity measures for ranking results, such as simple overlap . But this is problematic because queries such as "2008 population density by congressional district" illustrate a complex interaction between space, time and theme that simple overlap cannot capture. Without a comprehensive understanding of relevance and how it depends on user needs, current systems cannot serve more relevant documents and reduce search abandonment.

\section{Research Question}

Relevance is a fundamental but elusive concept in IR. Researchers hypothesize what is relevance by observing user search behavior. In this research, I seek to understand what is relevant to users when searching for geospatial data. Specifically, I want to know what concepts they use, implicitly or explicitly, while searching and if these concepts are valuable for improving relevance ranking. I will attempt to answer the following question:
\linebreak

\emph{How can the concepts that people use implicitly and explicitly when searching for geospatial data improve ranking in GIR systems to yield more relevant search results?}
\linebreak

I hypothesize that concepts like granularity, content type, timeliness, and spatial density, when weighted the same as footprint overlap during ranking will provide more relevant search results than existing ranking procedures as measured by system-based and user-based evaluations including MAP and relevance feedback scores. Employing these concepts should help the portal audience because their needs are naturally constrained. They are looking for data at or about a location (i.e., not navigational or transactional) for use in specific analysis or simply answer the question “what is the value of an attribute here?”.  In \gls{geographic_information_system} (\acrshort{GIS}, the aforementioned concepts are routinely used, so I expect them to be useful in search as well.

\section{Research Objectives}

The objectives of this research are as follows: 1) explore search behavior in the unique context of geospatial data search, 2) enrich the notion of geographic relevance by geospatial and non-geospatial concepts, and 3) test whether or not these concepts improve search result ranking and hopefully reduce search abandonment. I believe that these objectives are tangible because I have limited the scope of this research. I am not going to conclusively define geographic relevance nor make a robust search system for a portal. I will make no conclusive judgements about search user needs are or their spatial cognition. Alternatively, I will leverage stable IR techniques to answer my question. I will analyze search query logs, which is typically the best method for exploring user search behavior. I will borrow from the Cranfield testing paradigm (system-view) to quantitatively test system effectiveness, and I will corroborate this test with user relevance feedback (user-view). Overall, this research will be guided by the notion that relevance is a matter of satisfying a task at hand (epistemological view).