\chapter{Problem and Research Question} \label{ch:[chapter 3 label]}

\section{Problem Statement}

The motivating problem for this research is as follows:
\linebreak

\emph{Many search sessions on geospatial data portals end in failure or are abandoned.}
\linebreak

This problem is confirmed by user search behavior on Esri's OpenData geospatial data portals. Since 2017, dataset downloads have decreased from approximately 25\% to less than 5\% of sessions, and from 40\% to less than 5\% of sessions where search was used. It is much more likely that a user will execute a search, refine that search several times, and then exit the session. While there are multiple reasons for search abandonment, irrelevant results is often a leading cause. Abandonment behavior indicates that users cannot find relevant datasets that satisfy their needs. There are a number of related reasons for this failure.

First, portals use simplistic techniques for comparing a user's query to datasets. Most search systems rely primarily on syntactic similarity to rank documents. For example, a top SERP result shares more words with a user's query than any other result. Keyword similarity is an intuitive relevance criteria but suffers from a number of drawbacks including: bias towards larger and wordier dataset representations, agnosticism of user context, and a weak application of geographic knowledge. Ultimately, applied search similarity measures weakly handle semantics. Second, simplistic similarity measures are used because developers have a hard time applying knowledge about user needs. It is technically difficult to index datasets, especially when they're thematically heterogeneous and vary in completeness. Once datasets are indexed, reasoning on them is even more difficult. How should a developer know which metadata are most important? There are machine learning approaches that can help this decision, but typically developers end up using heuristics and commercial goals to guide algorithm design. Third, a weak understanding of GR means that there is little geographic knowledge applied to ranking algorithm development. GR is not well understood or agreed upon in the GIR community \cite{Purves2018} because we don't know what explicit and implicit concepts (both geospatial and non-geospatial) that users use when searching. As a result, GIR systems treat relevance as something more basic than it is.

% . Current indexing and ranking methods can't capture rich enough understanding of relevance

Given these reasons, itâ€™s understandable why portals only use simple geographic similarity measures for ranking results, such as simple spatial overlap. This is problematic because queries such as "2008 population density by congressional district" illustrate a complex interaction between space, time and theme that simple overlap doesn't capture. Without a comprehensive understanding of what concepts indicate relevance, current systems cannot serve more relevant documents and reduce search abandonment.

\section{Research Question}

In this research, I want to understand what concepts searchers use, implicitly or explicitly, and if these concepts are valuable for improving relevance ranking. I will attempt to answer the following question:
\linebreak

\emph{Can concepts (e.g., granularity) that people use implicitly and explicitly when searching for geospatial data improve ranking in GIR systems to yield more relevant search results?}
\linebreak

I hypothesize that concepts including granularity, content type, timeliness, spatial concentration, and magnitude are commonly articulated in user queries and are indicative of what users find relevant to their needs. Incorporating these concepts into relevance ranking will provide more relevant search results than existing ranking procedures as measured by system-based and user-based evaluations including MAP and click deviation. I believe that portal searchers are seeking to satisfy informational needs, not navigational or transactional needs. They are looking for data \emph{at} or \emph{about} a location for use in specific analysis or simply answer the question "what is the value of an attribute here?". In \gls{geographic_information_system} (\acrshort{GIS}, the aforementioned concepts are routinely used, so I expect them to be used in search as well.

% Relevance is a fundamental but elusive concept in IR. Researchers hypothesize what is relevance by observing user search behavior. 

\section{Research Objectives}

The objectives of this research are as follows: 1) explore search behavior in the context of geospatial data search, 2) enrich the notion of geographic relevance by geospatial and non-geospatial concepts, and 3) test whether or not these concepts improve search results and reduce search abandonment. These objectives are tangible because I have limited my scope to two phases-survey existing systems and user behavior (studies 1-3) and apply gained knowledge about concepts and behavior (studies 4-5). Using established IR analysis and evaluation methods, I will analyze search query logs, modify a search system according to my findings, and evaluate the system using system-view and user-view measures. I am not going to conclusively define geographic relevance nor catalog and incorporate all concepts discovered. I will engineer a simple ranking algorithm that attempts to utilize knowledge gained, not a concrete one. Overall, this research will be guided by the notion that relevance is a matter of satisfying a task at hand (epistemological view).