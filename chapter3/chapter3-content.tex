\chapter{Problem and Research Question} \label{ch:[chapter 3 label]}

\section{Problem Statement}

The motivating problem for this research is as follows:
\linebreak

\emph{Many search sessions on geospatial data portals end in failure or are abandoned.}
\linebreak

This problem is confirmed by recorded user search behavior on Esri's OpenData geospatial data portals (portals). Over the last two years, dataset downloads have decreased from approximately 25\% to less than 5\%, and from 40\% to less than 5\% for sessions where search was used. By the end of a search session, few users complete any goal conversion like download a dataset. It is much more likely that a user will execute a search, refine that search several times, and then exit the session. While there are multiple reasons for search abandonment, search ineffectiveness is often a leading cause, and it is likely in this case. This behavior indicates that users cannot find relevant datasets that satisfy their needs. There are a number of related reasons for this failure.

First, portals use simplistic techniques for comparing a user's query to datasets. Most search systems rely primarily on syntactic similarity to rank documents. For example, a top SERP result on a is placed at the top because it shares more words with a user's query than any other result. This approach is intuitive but suffers from a number of drawbacks including bias towards larger and wordier dataset representations, agnosticism towards user context, and a very weak application of geography. There are many successful algorithmic adjustments to this ranking approach, but ultimately its design handles semantics weakly. Second, simplistic techniques are used because developers have a hard time applying knowledge about user needs. It is technically difficult to index datasets, especially when they're thematically heterogeneous and vary in completeness. Once datasets are indexed, reasoning on them is even more difficult. For example, how should a developer know which metadata are most important and how to weigh them in a ranking algorithm? There are machine learning approaches that can guide this process, but typically developers end up using heuristics and commercial goals to guide design. Once a basic ranking algorithm is created, developers tend to focus on adding new features. Third, a weak understanding of GR means that there is little knowledge to guide indexing and ranking development. GR is not well understood or agreed upon in the GIR community \cite{Purves2018}. As a result, GIR systems treat relevance as something more basic than it is. Current indexing and ranking methods can't capture rich enough understanding of relevance because we don't know what explicit and implicit concepts (both geospatial and non-geospatial) that users use when searching.

Given these reasons, it’s understandable why portals only use simple spatial similarity measures for ranking results, such as simple overlap . But this is problematic because queries such as "2008 population density by congressional district" illustrate a complex interaction between space, time and theme that simple overlap cannot capture. Without a comprehensive understanding of relevance and how it depends on user needs, current systems cannot serve more relevant documents and reduce search abandonment.

\section{Research Question}

Relevance is a fundamental but elusive concept in IR. Researchers hypothesize what is relevance by observing user search behavior. In this research, I seek to understand what is relevant to users when searching for geospatial data. Specifically, I want to know what concepts they use, implicitly or explicitly, while searching and if these concepts are valuable for improving relevance ranking. I will attempt to answer the following question:
\linebreak

\emph{Can the concepts (e.g., granularity) that people use implicitly and explicitly when searching for geospatial data improve ranking in GIR systems to yield more relevant search results?}
\linebreak

I hypothesize that, when weighted the same as footprint overlap during ranking, several concepts including granularity, content type, timeliness, spatial concentration, and magnitude will provide more relevant search results than existing ranking procedures as measured by system-based and user-based evaluations including MAP and click deviation. Employing these concepts should help the portal audience because their needs are naturally constrained. They are looking for data at or about a location (i.e., not navigational or transactional) for use in specific analysis or simply answer the question “what is the value of an attribute here?”.  In \gls{geographic_information_system} (\acrshort{GIS}, the aforementioned concepts are routinely used, so I expect them to be useful in search as well.

\section{Research Objectives}

The objectives of this research are as follows: 1) explore search behavior in the unique context of geospatial data search, 2) enrich the notion of geographic relevance by geospatial and non-geospatial concepts, and 3) test whether or not these concepts improve search result ranking and hopefully reduce search abandonment. I will leverage established IR techniques to answer my research question. I believe that these objectives are tangible because I have limited the scope of this research to two phases-survey existing systems and user behavior (studies 1-3) and apply gained knowledge about concepts and behavior (studies 4-5). I will analyze search query logs, modify a search system according to my findings, and borrow techniques for system-view and user-view evaluations of the system. I am not going to conclusively define geographic relevance nor catalog and handle all concepts discovered. Nor will I  engineer a baseline ranking algorithm, merely one that attempts to utilize knowledge gained. Overall, this research will be guided by the notion that relevance is a matter of satisfying a task at hand (epistemological view).